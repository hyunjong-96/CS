# 데이터베이스 



<br>

-----------------------

### DB & DBMS

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ DB (DataBase)
  + 파일 시스템의 데이터 중복, 비 일관성, 검색 등의 문제를 해결하기 위해 구조화된 데이터 집합
+ DBMS (DataBaseManagementSystem)
  + 여러 사용자들이 DB를 사용할 수 있도록 해주는 소프트웨어
+ 스키마
  + 데이터베이스의 구조와 제약조건 등의 명세를 기술한 메타 데이터 집합
    + 외부스키마
      + 사용자에게 보이는 DB를 어떻게 보여줄것인지 기술 (응용 프로그램)
      + 실제 데이터베이스를 어떤 형식, 구조를 통해 사용자에게 보여줄것인가(workbench, ubuntu에서 DB를 보여주는거?)
    + 개념스키마
      - 데이터베이스에 저장되는 데이터와 그 관계를 정의 (논리 구조)
    + 내부스키마
      + 데이터베이스의 물리적 저장 구조 기술
+ 데이터베이스 특징
  + 데이터 독립성
    + DB의 하위 단계의 구조가 변경되어도 상위 단계에 영향을 미치지 않는 속성
    + 논리적 독립성
      + 응용 프로그램에 영향을 주지 않고 DB의 논리구조를 변경할 수 있는것
      + 즉, 개념 스키마를 변경해도 외부 스키마에 영향을 미치지 않는다

    + 물리적 독립성
      + 응용 프로그램이나 논리 구조에 영향을 주지 않고 DB의 물리적 구조를 변경할 수 있다.
      + 즉, 내부 스키마를 변경해도 외부, 개념 스키마에 영향을 미치지 않는다.

  + 데이터 무결성
    + 일관성과 정확성을 유지하여 데이터의 결함이 없도록 보호하는 기법
    + 일관성 : 데이터의 상태가 유지되는것
    + 정확성 : 데이터 중복x, 누락x

  + 데이터 보안성
    + 인가된 사용자만 데이터를 제어및 관리할 수 있다.

  + 데이터 일관성
    + 어떤 데이터 하나만 변경했을때 발생할 수 있는 불 일치성을 배제할 수 있다. (정합성이랑 비슷한 개념?)

  + 데이터 중복 최소화
    + 데이터를 통합해서 관리하기 때문에 파일 시스템의 단점중 하나인 중복 문제를 해결할 수 있다.




</details>

-----------------------

<br>



<br>

-----------------------

### 무결성

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 데이터의 정확성, 일관성을 보장하는 것
  + 정확성 : 중복과 누락없는 것
  + 일관성 : 성질이 변하지 않고 유지되는 것

+ 무결성 제약 조건 종류
  + 개체 무결성
    + 기본키는 Null일 수 없고, 하나의 값만 존재해야한다.

  + 참조 무결성
    + 외래키를 참조할 수 없는 값을 가질 수 없다. Null이나 fk만 허용한다.

  + Null 무결성
    + 특정 속성은 Null을 가질 수 없다.

  + 고유 무결성
    + 특정 속성은 중복되는 값을 가질 수 없다.

  + 키 무결성
    + 하나의 테이블에는 적어도 하나의 키가 있어야한다.

  + 도메인 무결성
    + 속성값은 해당 속성의 도메인에 속한 값이어야한다.
    + 성별 속성은 무조건 남,녀만 와야한다.



</details>

-----------------------

<br>



<br>

-----------------------

### Key

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 튜블플 구분할수 있는 유일한 속성
+ 종류
  + 슈퍼키 : 유일성을 만족하는 속성
  + 후보키 : 유일성과 최소성을 만족하는 속성
  + 기본키 : 후보키 중에서 선택한 속성, 특정 튜플을 유일하게 식별할수 있는 속성이며 Null을 허용하지 않는다.
  + 대체키 : 기본키를 제외한 나머지 후보키
  + 외래키 : 다른 튜플을 식별할 수 있는 속성



</details>

-----------------------

<br>



<br>

-----------------------

### 외래키와 참조 무결성

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 외래키는 참조 무결성을 지키기 위해 restricted, cascade와 같은 개념을 적용할 수 있다.
+ restricted
  + 수정 삭제시, 해당 개체를 참조하고 있는 개체가 있다면 연산을 취소

+ cascade
  + 수정 삭제시, 해당 개체를 참조하고 있는 개체도 함께 수정 또는 삭제



</details>

-----------------------

<br>



<br>

-----------------------

### 데이터베이스 성능

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ DB는 데이터를 블럭단위로 읽고 저장한다. 
+ DB의 튜닝 핵심은 블럭단위 I/O를 줄이는것.
+ 디스크 I/O와 메모리 I/O
  + 디스크  I/O : 디스크의 Access 암이 움직여 데이터가 저장된 위치로 이동하고 디스크 헤더를 통해 데이터를 읽고 쓴다
  + 메모리 I/O : 전기적 신호로 데이터를 읽고 쓴다.
  + 디스크 I/O가 메모리 I/O보다 10000배 느리다. 하지만 메모리는 한정된 자원이므로, 디스크 I/O를 최소화하고 버퍼 캐시 효율을 높이는 것이 I/O 튜닝의 목적이다.
+ 디스크의 성능을 향상시키기 위해서는 디스크 헤더의 위치 이동없이 얼마나 많은 데이터를 한번에 기록하느냐로 결정될 수 있다.
+ Sequence I/O와 Random I/O
  + Sequence 엑세스 :  레코드간 논리적 또는 물리적인 순서를 따라 차례대로 읽어나가는 방식
    + 레코드간 포인터를 이용해 논리적으로 연결되어 있어 포인터를 따라 스캔 (효율)

  + Random 엑세스 : 레코드간 논리적 또는 물리적인 순서를 따르지 않고, 한 건을 읽기 위해 한 블록씩 접근 (비효율)
  + <img width="400" alt="image" src="https://user-images.githubusercontent.com/57162257/192932757-86dc0178-a535-4adb-ac59-e4cc55f7776d.png">
  + <img width="400" alt="image" src="https://user-images.githubusercontent.com/57162257/192932845-58d04663-e93a-41a8-87df-49052aa48778.png">
    + sequence I/O : 5 (B+Tree ?)
    + Random I/O : 1,2,3,4,6 (B-Tree ?)

  + Sequence I/O 비중을 늘리고 Random I/O의 비중을 줄인다.
    + Sequence I/O의 비중 늘리기 : 읽은 총 건수에 대해서 결과 집합으로 선택되는 비중을 높여야한다. (얼마나 적은 레코드를 읽는가)
      + 조건절에 사용된 컬럼, 연산자 형태, 인덱스 구성에 따라 효율이 구성됨.

    + Random I/O의 비중 낮추기 
      + 인덱스로 만족하는 결과를 가져와 Random 엑세스를 수행하여 결과를 추출하지만 선택된 결과에 비해 너무 많은 Random 엑세스 발생.
      + 인덱스에 조건절 컬럼을 추가해 Random 엑세스 감소

    + http://wiki.gurubee.net/pages/viewpage.action?pageId=27428135
+ DB 버퍼 캐시
  + 디스크에서 읽은 데이터 블럭을 메모리상에 캐싱하여 같은 블럭에 대한 반복적 I/O call을 줄일수 있다.
    + LRU알고리즘에 의해 관리되며 LRU알고리즘에 의해 삭제되지 않았다면 재사용
+ 캐시 히트율 (BCHR)
  + 데이터를 캐시된 정보에서 얼마나 가지고 오는지 구하는것
    + 논리적 I/O : SQL을 처리하는 과정에서 Buffer Cache에서 발생한 총 블록 I/O (메모리에 접근하여 가져온 블록 수)
    + 물리적 I/O : 디스크에서 발생한 총 블록 I/O

  + 공식
    + BCHR = (1-(`물리적 I/O`/`논리적  I/O`))*100 = (`캐시에서 찾은 블록 수` / `총 읽은 블록수`) * 100
+ I/O 효율화 튜닝 핵심
  + `논리적 블록 요청 횟수`를 줄이고, `물리적 디스크에서 읽어야할 블록 수`를 줄이는것




</details>

-----------------------

<br>



<br>

-----------------------

### 정규화

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 이상현상을 제거하기 위해 테이블을 분리하는 작업
+ 이상현상
  + 삽입 이상
    + 특정 데이터가 존재하지 않아 추가하고 싶은 데이터를 추가하지 못하는 현상
    + 또는 불필요한 데이터를 함께 추가해야하는 현상
    
  + 삭제 이상
    + 특정 데이터를 삭제할때 원치 않은 데이터도 삭제되는 현상
  
  + 갱신 이상
    + 데이터를 수정했는데 같은 속성이지만 다른 값을 가지는 불일치성이 생기는 현상
      + 데이터 정합성의 불일치
  
+ 종류
  + 제 1정규화
    + 모든 속성값은 원자성을 갖는다.

  + 제 2정규화
    + 제 1정규화 + 완전 함수정 종속
    + 완전 함수적 종속 : 기본키의 부분집합이 결정자이지 않는것
    + 완전 함수적 종속을 만족하지 않는 경우
      + <img width="522" alt="image" src="https://user-images.githubusercontent.com/57162257/190955012-8b677625-7b6b-4996-925e-9cc4bf1afbd5.png">
    
  + 제 3정규화
    + 제 2정규화 + 이행적 종속이 아닌것
    + 이행적 종속 : a->b, b->c 일때 a->c인것.
      + <img width="336" alt="image" src="https://user-images.githubusercontent.com/57162257/190955096-c3338e96-8768-4db9-8f2f-17892b9d5020.png">
    
  + BCNF
    + 제 3정규화 + 모든 결정자가 후보키
    + 모든 결정자가 후보키가 아닌 경우
      + <img width="406" alt="image" src="https://user-images.githubusercontent.com/57162257/190955207-b5bf4935-4e7c-4d44-b0ac-5bff61b53a6e.png">



</details>

-----------------------

<br>



<br>

-----------------------

### 반 정규화

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 의도적으로 정규화를 위배해 성능 향상 및 편의성을 이루는 과정
+ 시스템의 성능이 향상될 수 있지만 데이터의 일관성은 저하될 수 있다.
+ 장점
  + Join비용이 줄어들어 빠른 조회가 가능하다.
  + 조회 쿼리가 간단해진다.

+ 단점
  + 데이터의 수정, 삭제 비용이 비싸다
  + 데이터를 중복저장하여 더 많은 저장공간이 필요.



</details>

-----------------------

<br>



<br>

-----------------------

### 트랜잭션

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 데이터베이스의 상태를 변경하기 위한 작업 단위
+ 특징 (ACID)
  + 원자성 (Automicity)
    + 트랜잭션의 결과는 모두 반영되거나 모두 반영되지 않아야한다.

  + 일관성 (Consistency)
    + 트랜잭션의 결과로 데이터베이스의 상태가 모순되지 않아야한다.

  + 격리성 (Isolation)
    + 트랜잭션이 자원을 사용하고있다면 다른 트랜잭션의 접근을 제한하는것.

  + 지속성 (Durability)
    + 트랜잭션이 성공정으로 수행되면 결과는 데이터베이스에 영구적으로 저장된다.



</details>

-----------------------

<br>



<br>

-----------------------

### 회복

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 문제가 발생했을 때 Rollback이 수행되고 UNDO, REDO가 발생하여 문제가 발생되기 전 상태로 돌아가는 것
+ check point
  + 로그 파일에 체크포인트를 저장하고 문제 발생시 check point 이후에 처리된 작업들을 회복시키는 것.

+ UNDO
  + 트랜잭션이 commit되지 않은 상태에서 문제 발생시, 해당 작업이 없던 일로 처리하는 작업

+ REDO
  + 트랜잭션이 commit된 후 문제 발생시, REDO로 check poin지점으로 돌아가 저장된 로그를 통해 commit지점까지 복구하는 작업.



</details>

-----------------------

<br>



<br>

-----------------------

### 트랜잭션 격리성 문제

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 동시에 여러 트랜잭션이 수행 될 때 각 트랜잭션이 얼마만큼의 고립성을 가지는지 나타내는 것
+ 사용 이유
  + 동시성과 일관성을 유지하기 위함으로써, 일관성이 너무 높으면 병목 현상이 발생하여 응답이 지연되고, 동시성이 너무 높으면 데이터가 꼬일 위험이 있게 된다. 동시성과 일관성을 적절히 맞추기 위해 사용하는 방법 중 하나가 트랜잭션 격리이다.
+ 문제
  + Dirty Read
    + 완료되지 않은 상태의 데이터를 읽어오는 문제.

  + UnRepeatable Read
    + 동일한 조회를 하였을때 다른 결과를 읽어오는 문제

  + Phantom Read
    + 있었던 데이터가 사라지거나 없었던 데이터가 생기는 문제

+ 종류
  + Read UnCommited
    + 데이터를 변경한 트랜잭션의 commit, rollback 여부 상관없이 트랜잭션에게 보여주는 격리성 수준
  + Read Commited
    - commit을 수행한 트랜잭션의 결과만 조회할 수 있는 격리 수준
    - orcle의 격리 수준
    - Commit() 이후의 데이터만 읽을 수 있기 때문에 Dirty Read는 발생하지 않는다.
    - 다른 트랜잭션이 수정 중인 데이터는 Undo영역의 데이터를 읽어오고, commit()된 후의 데이터를 조회할 때는 Record영역의 데이터를 읽어 오기 때문에 Non Repetable Read와 Phantom Read 가 발생한다.
  + Repetable Read
    + 트랜잭션의 ID를 부여하여 자신 보다 낮은 ID의 트랜잭션 결과만 조회하는 격리 방식
    + MySQL의 격리 수준
    + 데이터 변경시 이전 데이터를 트랜잭션 ID와 함께 Undo영역에 저장하고 변경된 데이터는 Record 영역에 저장한다.
      + 이러한 변경 방식을 MVCC (Multiple Version Concurrency Control)이라고 한다.
        + Concurrency : 동시성
    + 트랜잭션 ID를 통해 Repetable Read가 발생하지 않는다.
    + InnoDB를 제외하고는 Repetable Read에서는 Pantom Read는 발생한다.
      + InnoDB에서는 Consistent Read와 Next key Lock으로 팬텀 리드가 발생하지 않는다.
      + mysql의 MyIAM엔진에서 테스트해보면 팬텀리드가 발생하지만 InnoDB에서 동일하게 수행하면 팬텀리드는 발생하지 않는다.
  + Serializable
    + 읽기 작업과 쓰기 작업 모두 락을 걸어 다른 트랜잭션은 해당 자원에 접근할 수 없다
    + 일관성이 가장 높고 동시성이 가장 낮은 격리 수준



</details>

-----------------------

<br>



<br>

-----------------------

### Lock

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ Lock이란 트랜잭션 처리의 순차성을 보장하기 위한 방법.
+ 종류
  + 공유 락 (S- Lock)
    + 데이터를 읽을 때 사용되는 락.
    + S-Lock이 걸려있을때 S-Lock는 동시 접근이 가능하다. 하지만 X-Lcok은 접근이 불가능하다.
    + SELECT for Share
  + 베타 락 (Exclusive - Lock)
    + 데이터를 변경 할 때 사용되는 락
    + X-Lock이 해제될 때까지 다른 트랜잭션은 해당 자원에 접근이 불가능하다.
    + SELECT for UPDATE, UPDATE, DELETE
  + Gap Lock
    + DB index record의 gap에 걸리는 락
    + gap이란 index 중 데이터베이스에 실제 record가 없는 부분을 말한다.
    + id = 13, id = 17이 있는 테이블 t가 있을때, index record에는 id<=12, 14 <= id <= 16, 18<=id 는 실제 존재하지 않는 record이므로 해당 범위를 gap이라고한다.
    + 즉 gap lock이란 select for update와 같이 락을 걸어주는 조회쿼리시 **범위**를 사용하였을때, 실제 존재하지 않는 record에 대해 락을 걸어주어 다른 트랜잭션이 해당 gap lock이 걸려있는 레코드 부분에 있어 추가, 수정, 삭제를 못하도록 하는것이다.
  + Next Key Lock
    + Record Lock과 Gap Lock이 함께 사용되는 Lock으로 InnoDB에서 Phantom Read를 방지하기 위해 사용된다.
    + 위에서 설명했듯이 조회한 범위 내에 존재하지 않는 index에 락을 걸어준다.
    + 사실 gap lock에는 범위에 없는 index뿐만 아니라 앞 뒤 범위도 포함이 되어서 gap lock이 발생한다. (이래야 phantom read를 더 효율적으로 잡을 수 있다고 한다.)
      + next key lock은 보조 인덱스를 사용하기 때문에 보조 인덱스를 만들어줘야 gap lock이 발생한다. 안그러면 테이블 전체에 락이 걸린다.
+ 락의 해제 타이밍
  + commit
  + rollback



</details>

-----------------------

<br>



<br>

-----------------------

### MySQL의 Lock

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ MySQL은 기본적으로 Repeatable Read의 고립 수준을 가진다. 그리고 기본 엔진인 InnoDB는 MVCC를 사용한다.
+ MVCC란 Multi Version Concurency Control의 약자로써 트랜잭션을 지원하는 DBMS가 락을 사용하지 않고 일관된 읽기를 제공하는 것을 목적으로 제공하는 기술.
  + 하나의 레코드에 대해 여러 버전의 레코드를 관리한다.
  + InnDB는 언두 로그에 버전별 레코드를 저장한다.

+ 일관된 읽기 (Consistent Read)
  + InnoDB에서 MVCC를 통해 다른 트랜잭션이 가지는 Lock을 기다리지 않고 읽기 작업을 수행할 수 있는것.
  + 특정 트랜잭션이 레코드를 변경중일때 Lock이 걸리게 된다. 하지만 MVCC에 의해 UNDO영역에 다른 버전의 레코드가 관리되고 있기 때문에 해당 Lock을 기다리지 않고 SELECT작업을 수행할 수 있는것.

+ 격리성 수준
  + Repeatable Read
    + MVCC에 의해 consistent read를 하여 다른 lock에 영향없이 일관된 읽기가 가능하다 (non reapeatable read 해결)
    + update 시에는 다른 트랜잭션이 수정한 값이 적용되어 보이게된다. 이는 다른 트랜잭션에 의해 해당 데이터가 수정되었음에도 이전 snapshot을 사용하는 것은 정합성이 깨지기 때문에 row에 대한 consistent read를 초기화하고 최근 상태의 row를 보여주게 된다. (update한 row를 제외한 나머지 row는 모두 snapshot)

  + Read Commited
    + 첫 Read operation에서 찍은 snapshot만 사용하는 Repeatable Read와 달리, Read Commited는 Read operation을 수행할때마다 snapshot을 찍는다. 때문에 Read operation시점마다 새로 commit된 데이터가 보이게된다.

  + Read UnCommited
  + Serializable




</details>

-----------------------

<br>



<br>

-----------------------

### Index

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스의 검색 속도를 향상시키기 위한 자료구조
+ Indexing을 사용하지 않으면 조회시 Table Full Scan으로 검색 속도가 느리다.
+ Index의 컬럼 선정 기준
  + 카디널리티가 높은 컬럼 (중복도가 낮은 컬럼)
  + 이유
    + 인덱싱의 최대 효율을 내기 위해 Index로 많은 부분을 걸러내야하기 때문이다
  + Index의 복수 컬럼 선정
    + 카디널리티가 높은 순으로 선정한다.
+ 자료구조
  + 해시 테이블
    + key에 대한 해시코드를 통해 데이터를 찾아 O(1)의 시간이 걸린다.
    + 해시 테이블은 등호연산(=)일때는 효율적이지만 데이터들이 정렬되어있지 않기 떄문에 부등호(>,<)연산시 효율적이지 못하다.
  + B - Tree
    + Leaf Node와 그 외 Node로 구성되어있다.
    + 하나의 노드에 key와 데이터가 저장되어있다.
    + 같은 레벨의 노드의 key는 정렬되어있다.
    + 시간복잡도
      + 탐색 : O(logN)
      + 삽입 삭제 : O(h)
    + 장점
      + 노드에 데이터가 저장되어있어 메모리에서 바로 데이터를 가져올 수 있다.
      + key가 정렬되어있어 부등호 연산에 효율적이다.
    + 단점
      + 삽입,삭제시 자동 정렬로 인해 성능이 저하된다.
      + 모든 데이터를 순회할때는 트리의 모든 노드를 방문해야한다.
  + B + Tree
    + B-Tree에서 탐색을 위해 노드를 찾아서 이동해야한다는 단점을 LinkedList를 통해 해결
    + Inner Node와 Leaf Node로 구성되어있다.
    + Inner Node에 key만 정렬되서 저장되어있고 데이터는 Leaf Node에 LinkedList로 연결되어 저장되어있다.
    + 뿐만 아니라 다른 Inner Node에서도 같은 레벨의 노드끼리는 LinkedList로 연결되어있기 때문에 다음 노드로 이동할 수 있다.
    + 장점
      + Leaf Node가 LinkedList로 연결되어있어 선형탐색이 가능하고 부등호 연산에 효율적이다.
      + leaf node를 제외하고 다른 노드는 데이터를 저장하고 있지 않기 때문에 메모리를 더 확보할수 있다. 그렇기 때문에 하나의 node에서 더 많은 포인터를 가질 수 있기 때문에 트리의 높이가 낮아 검색 속도를 높일 수 있다.
+ Index에서 DML이 미치는 영향
  + Insert
    + Index데이터 추가시, 해당 노드에 공간이 부족하다면 기존 노드를 분리하여 저장될수 있도록 재정렬된다. 저장 과정에 재정렬 과정이 추가되고 index삽입으로 인한 노드 파편화(Insert split)로 성능이 저하될 수 있다.

  + Delete
    + Index에서 데이터를 삭제하는 경우, Index데이터가 삭제되는 것이 아닌, 사용하지 않음이라는 표시만 해두게 된다. 그렇기 때문에 공간적으로, 성능적으로 효율적이지 못하다.

  + Update
    + Index에는 Update라는 개념이 없다. 해당 Index데이터를 사용하지 않음으로 표시한 후, 새로운 Index데이터를 추가하는 것이기 때문에 다른 DML보다 더 좋지 못한 성능이 발생할수 있다.
    + 즉, Update시 Delete, Insert 발생

  + 인덱스 재구성(Index Reorganize) 와 인덱스 리빌드(Index Rebuild)
    + 인덱스 재구성
      + 정렬되지 않은 Index순서를 다시 순서대로 정렬시키는 것.

    + 인덱스 리빌드
      + Index의 순서만 정렬하여 구성하는 인덱스 재구성과 다르게 인덱스를 완전히 삭제하고 새로 구성하는 것.
      + 일반적으로 인덱스 리빌드에 소요되는 시간과 리소스가 인덱스 재구성보다 크지만, 일정 수준 이상(30%이상)의 조각화 발생시 인덱스 리빌드를 진행하여 인덱스 조각화 문제를 해결할 수 있다.

+ Index를 선정하기 좋은 경우
  + DML이 자주 발생하지 않는 테이블
  + where절에 많이 사용하는 컬럼
  + join이 자주사용되는 외래키
  + 카디널리티가 높은 컬럼
  + 선택도가 낮은 컬럼
    + 
  + 크기가 큰 테이블
+ 주의사항
  + between, like, <, > 등의 범위 조건에 사용된 컬럼은 인덱스를 타지만, 그 뒤의 인덱스 컬럼은 인덱스로 사용되지 않는다.
  + like의 경우 'str%'같이 좌측 일치 패턴만 인덱스가 가능하다.
  + =, IN 조건의 칼럼은 뒤의 인덱스 칼럼들을 인덱스로 사용한다
    + IN조건 안에 서브쿼리를 넣게 되면 서브쿼리의 외부를 먼저 실행하고, in은 체크조건으로 실행되어 성능이슈 발생가능.

  + AND연산자는 각 조건들이 읽어와야할 ROW수를 줄이지만 OR연산은 비교해야할 ROW수를 늘리기 떄문에 Full Table Scan이 발생할 수 있다.
  + 인덱스로 사용하는 컬럼 그대로 사용해야한다.
    + where salad * 10 > 15000;은 인덱스를 타지 못한다.
    + Where salary > 150000 / 10;은 인덱스를 사용한다.




</details>

-----------------------

<br>



<br>

-----------------------

### Page Split

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ 페이지 조각화는 특정 컬럼을 기준으로 정렬되어있는 페이지에서 중간에 특정 데이터를 추가한다면 정렬되어있던 페이지의 순서가 뒤죽박죽 되어버리는 것을 이야기한다.
+ 이는 Insert시 발생하는데, 페이지 조각화로 인해 Index 조회시 거쳐야 하는 페이지가 많아져 조회 성능을 떨어트리게 된다.



</details>

-----------------------

<br>



<br>

-----------------------

### B-Tree 비교

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ B-Tree vs Red-Black Tree
  + 공통점
    + 항상 좌,우 노드 개수의 밸런스를 유지하기 때문에 탐색 O(logN)의 시간복잡도를 보장

  + 차이점
    + Red-Black Tree는 각 노드에 하나의 데이터만 저장할 수있다. 하지만 B-Tree는 각 노드에 여러 데이터를 저장할 수 있고 배열로 저장되어있기 때문에 같은 노드에 있는 데이터에 접근할때 참조 포인터 없이 다음 인덱스에 접근 할 수 있다.
      + 참조는 접근하려는 주소를 알아내기 위해 CPU내부적으로 많은 연산을 한다. 하지만 배열은 메모리 공간에 차례대로 저장되어있으므로 접근할 주소의 배열인덱스를 바로 알 수 있다.

    + B-Tree 사용

+ B-Tree vs 배열
  + 배열은 연속으로 메모리 공간에 저장되어있기 때문에 조회시 B-Tree보다 빠르다. 하지만 배열은 추가,삭제 시 배열의 복사가 발생하므로 B-Tree보다 월등히 느리게 된다.
  + B-Tree를 사용

+ B-Tree vs HashTable
  + HashTable은 조회시 O(1)의 빠른 시간으로 데이터에 접근할 수 있다. 하지만 부등호 연산에는 효율적이지 못하지만 B-Tree는 정렬된 Tree이기때문에 부등호 연산에 효율적이다.




</details>

-----------------------

<br>



<br>

-----------------------

### 클러스터 인덱스, 논 클러스터 인덱스

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ Heap 구조

  + Index가 존재하지 않는 테이블 구조
  + 클러스터드 인덱스 없이 테이블에 정렬없이 순차적으로 저장되는 구조

+ 클러스터 인덱스 (Cluster Index)

  + <img width="500" alt="image" src="https://user-images.githubusercontent.com/57162257/194693412-7b9da318-d3b6-40b6-9bbd-c3c368887b3d.png">
  + 생성 ` CREATED CLUSTERED INDEX [INDEX 이름] ON [테이블 이름] ([인덱스 컬럼1],[인덱스 컬럼2])`
  + Root, Intermediate, Leaf(Data) Page로 구성
  + 순차적으로 저장되는 Heap구조와 다르게, 클러스터 인덱스 컬럼을 기준으로 Data Page가 정렬된 상태로 저장
  + Leaf Page에 실제 데이터가 정렬된 상태로 위치하며, 다른 페이지는 Leaf Page로 이동하기 위한 Index컬럼과 참조 포인터로 이루어져있다.
  + 클러스터 인덱스를 Unique 인덱스로 생성하지 않으면 고유 식별자인 행이 추가되어 고유 Index임을 나타낸다.
  + PRIMARY KEY를 설정한 테이블에서는 클러스터 인덱스를 별도로 설정하지 않는다면 PK로 클러스터 인덱스가 자동 생성된다.
  + 인덱스를 기준으로 정렬되어 저장되어있기 때문에 검색에서 효율성이 좋다.
    하지만 삽입,수정시 정렬된 데이터를 재정렬하는 과정으로 많은 비용이 소모된다.
  + 고려 사항
    + 클러스터 인덱스 컬럼을 기준으로 정렬되기 때문에 클러스터 인덱스는 하나의 인덱스만 생성할 수 있다.
    + 클러스터 인덱스 컬럼은 성능최적화를 위해 자주사용하는 컬럼이나 고유값을 많이 가지는 칼럼으로 생성하는것이 좋다.
    + ORDERY BY, GROUP BY는 정렬 동작이 수행되기 때문에 정렬상태의 클러스터 인덱스에서 사용하면 많은 리소스가 소비되는 정렬 과정을 생략할 수 있다.
    + 정렬상태의 클러스터 인덱스에서 인덱스에 대해 BETWEEN, <, > 등의 범위 조회시 빠르게 조회가 가능하다.
    + 너무 많은 클러스터 인덱스 컬럼은 좋지못하다
      + 논클러스터 + 클러스터 인덱스 구조일때, 논 클러스터 인덱스에서 데이터에 접근할때 발생하는 Key Look Up은 클러스터 인덱스를 사용하여 데이터에 접근하기 때문에 너무 많은 클러스터 인덱스를 가지고 있다면 그만큼 논 클러스터 인덱스의 크기도 비대해 지게된다.
    + Join조건을 많이 사용하는 테이블에서 사용하는 경우 좋다.
  + Clustered Index Seek
    + Root페이지에서 Leaf 페이지까지 클러스터 인덱스 컬럼 탐색을 통해 데이터를 가져오는 방법
    + 인덱스를 타고 특정범위의 결과만 불러올수 있기 때문에 빠르다.
  + Clustered Index Scan
    + 클러스터 인덱스가 존재하지만, 인덱스 키로 지정된 열을 탐색조건으로 사용할 수 없는 경우 사용되는 방법
    + 인덱스키로 찾을수 없는 열을 찾기 위해 모든 인덱스를 탐색하는 방법 (Table Scan과 유사)
  + 종류
    + Dense Index
      + <img width="200" alt="image" src="https://user-images.githubusercontent.com/57162257/193433715-82ba715a-b656-4aed-b7b2-53a7a10a7d0b.png">
      + DB에 있는 모든 검색 키에 대해서 주소값이 1대1로 배정된 형태.
      + 모든 검색키에 대한 주소값을 가지고 있기 때문에 검색이 빠르다.
        하지만 많은 저장 공간이 필요하다.

    + Spare Index
      + <img width="200" alt="image" src="https://user-images.githubusercontent.com/57162257/193433728-124b88e8-8af4-4486-94db-b1d903531721.png">
      + DB에 있는 일부 검색 키에 대해서 주소 범위 저장.
      + 검색키 일부만을 가지고 있기 떄문에 Dense Index보다는 검색이 느리고 삽입,삭제시 주소 범위를 갱신하는 과정에서 많은 비용이 발생하지만 적은 저장공간이 필요하다.

+ Non-Cluster 인덱스
  + <img width="500" alt="image" src="https://user-images.githubusercontent.com/57162257/194694432-8b08b7db-14f5-4460-8c91-f958c8e89fb3.png">

  + 생성 : `  CREATED INDEX [인덱스 이름] ON [테이블 이름] ON ([인덱스 컬럼1],[인덱스 컬럼2])`

  + Root, Intermediate, Leaf로 구성되어있으며 Leaf Page와 Data Page가 각각 분리되어있다.

  + 클러스터 인덱스와 달리 인덱스를 기준으로 Data Page의 데이터가 정렬되지 않는다.

  + Leaf Page의 Data Page접근

    + Look Up
      + 인덱스를 통해 찾을 수 없는 열 데이터를 실제 데이터가 저장되어있는 위치에서 필요한 데이터를 찾아오는 것.
    + `RID Look Up`
      + 논 클러스터 인덱스 + Heap
      + `RID (Row ID)`를 통해 Heap에 있는 실제 데이터에 접근할 수 있다.
        + RID = 파일 식별자 + 데이터 페이지 번호 + 데이터 페이지내의 행 번호
    + `Key Look Up`
      + 논 클러스터 인덱스 + 클러스터 인덱스
      + RID가 아닌 `클러스터 인덱스의 Key`를 통해 클러스터 인덱스에서 데이터에 접근할 수 있다.

  + 고려사항

    + 한 개의 인덱스만 생성가능한 클러스터 인덱스와 달리, 인덱스에 인한 정렬 기준이 존재하지 않기 때문에 한개 이상의 인덱스 생성이 가능하다.
    + 하지만 여러개의 논클러스터 인덱스가 있는 경우 옵티마이저에 의해 해당 쿼리에서 가장 효율이 좋은 인덱스를 선택해 하나의 인덱스만 적용된다.
      + 모든 인덱스 컬럼을 사용해야한다면 복합 인덱스를 사용.
    + 인덱스 기준으로 정렬되어 있지 않기 때문에 범위조건 사용시 검색이 느리고 leaf page에서 한번더 조회를 해야하기 때문에 검색이 느리다. 데이터 추가,수정시 Data Page 구조 변경없이 Leaf 페이지 정보만 변경해주면 되기 때문에 클러스터 인덱스 보다 변경이 유리하다.

  + Non Cluster Index Seek

    + 논클러스터 인덱스가 존재하고, 인덱스 키로 지정된 컬럼으로 탐색 조건으로 사용된 경우

  + Non Cluster Index Scan

    + 논클러스터 인덱스가 존재하지만, 열 데이터가 부족하여 탐색조건으로 사용되기 부족한 경우

      + 전화번호 컬럼을 인덱스로 사용했을때, 탐색조건으로 
        전화번호의 다섯번째 (하이픈 뒤)가 7이고 여섯번째와 일곱번째의 차가 3인 데이터를 찾고자할때

        쿼리로 표현하자면 where 전화번호 like '___-7%' AND ABS(SUBSTRING(전화번호, 6, 1) - SUBSTRING(전화번호, 7, 1)) = 3 으로 표현하기 때문에 인덱스만으로는 데이터를 찾을 수 없는 경우.




</details>

-----------------------

<br>



<br>

-----------------------

### Include Column (feat. Covering Query, Convered Index)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

- 생성한 Index내에 요구한 데이터(열 데이터)가 없다면 LookUp과정이 발생하여 조회 속도가 느려질수 있다.
  만약 Index내에 요구한 데이터가 모두 존재한다면 LookUp과정없이 Index수준에서 처리가 가능하기 때문에 조회속도가 빨라진다.
- 그렇다고 Index key 컬럼에 많은 컬럼을 넣게 된다면 Index가 복잡해지고 저장공간을 많이 차지하기 때문에 성능이 떨어지게 된다.
- `Include Colume`는 조회하려는 컬럼을 Index key 컬럼에 포함시키지 않고도 Index Page에서 사용할 수 있게 해주는 방법.
- 요구하는 데이터를 Index 수준에서 모두 처리할 수 있게 하는 쿼리를 `Convering Query`, 사용된 `Index를 Covered Index`라고 한다.
- Index Key 컬럼은 최대 32개의 컬럼, 1700byte의 제한이 있지만, Included Colume은 최대 1023개의 컬럼 설정이 가능하다.
- 특징
  - Leaf Page에 Include Colume을 저장하기 때문에 Index key 컬럼에 영향을 주지 않는다.
  - Index수준에서 요구하는 데이터를 처리할수 있기 때문에 LookUp이 발생하지 않아 I/O를 줄여 빠른 조회가 가능하다.
  - 논 클러스터 인덱스에서만 Included Colume생성 가능.
    - 클러스터 인덱스는 Leaf Page가 Data Page이기 때문에 별도로 컬럼이 추가된 구조가 필요없기 때문이다.
- 생성 : ` CREATED INDEX [인덱스 이름] ON [테이블 이름] ([인덱스 컬럼1],[인덱스 컬럼2]) INCLUDE([추가 컬럼1],[추가 컬럼2]) `



</details>

-----------------------

<br>



<br>

-----------------------

### Scan

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ Table Full Scan
  + 테이블의 속한 값을 모두 읽어 원하는 값을 찾는다.

+ Index Range Scan
  + leaft node까지 수직 탐색 후, LinkedList를 이용해서 범위 탐색이 가능하다.

+ Index Full Scan
  + 모든 값을 읽지않고 Index만 읽어서 탐색할 수 있기 때문에 Table Full Scan보다 비용이 저렴하다.
  + 첫번째 leaft node까지 수직 탐색 후,  리프 노드 전체를 탐색



</details>

-----------------------

<br>



<br>

-----------------------

### 옵티마이저

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ 옵티마이저란, SQL을 효율적으로 수행할 최적의 처리 경로를 생성해주는 DBMS의 핵심 엔진.
+ 사용자가 SQL로 결과를 요청하면, 이를 생성하는데 필요한 처리경로를 옵티마이저가 자동으로 생성
+ SQL 최적화 과정
  1. SQL을 수행하기 위해 후보가 될만한 실행 계획을 선택한다.
  2. 미리 수집해놓은 오브젝트 통계 및 시스템 통계 정보를 통해 각 실행 계획의 예상 비용을 산정한다.
  3. 각 실행 계획의 예상 비용중 가장 효율적인 실행 계획을 선정해서 실행한다.
+ 종류
  + 규칙 기반 옵티마이저 (Plain Base Optimizer - PBO)
    + 실행 속도가 빠른순으로 우선순위를 정하고, 우선순위가 높은 방법을 채택하는 방법
    + 우선순위 : 처리 경로를 선정하기 위한 우선순위로서, 인덱스구조, 연산, 조건절이 순서를 결정짓는 요소
      - ROWID를 사용한 단일 행, 클러스터 조인을 사용한 단일 행, 복합 컬럼 INDEX, 단일 컬럼 INDEX, FULL TABLE SCAN 등의 순서로 우선순위를 선정한다.

  + 비용 기반 옵티마이저 (Cost Base Optimizer - CBO)
    + 비용을 기반으로 최적의 처리경로를 선택하는 방법
      + 비용 : 쿼리를 수행하는데 걸리는 일 양, 처리 시간

    + CBO는 최대 2천개의 실행 계획을 세운뒤 비용이 최소한으로 나오는 실행 계획을 예상치로 판단한다.
      + 예상치 : 테이블, 컬럼, 인덱스, 시스템들의 통계 정보(I/O, CPU)를 이용

+ 옵티마이저에게 영향을 끼치는 요소
  + SQL과 연산자 형태
    + 동일한 결과가 나와도 SQL의 구성과 연산자에 따라 옵티마이저는 다른 실행 계획을 선택한다.

  + 옵티마이징 팩터
    + 동일한 쿼리를 사용해도 인덱스, 파티셔닝에 따른 옵티마이징 팩터에 의해 옵티마이저는 다른 실행 계획을 선택한다.

  + DBMS 제약조건
    + PK, FK, Not Null과 같은 제약정보는 옵티마이저의 성능에 영향을 끼친다.
      + count를 사용할때, INDEX에 NOT NULL제약조건이 있다면 이를 이용한다.

  + 통계 정보
    + 오브젝트 통계정보, 시스템 통계정보 등은 옵티마이저의 최적화 작업에 절대적인 영향을 끼친다.
    + 종류
      + 테이블
        + 테이블의 총 컬럼 수
        + 테이블이 차지하는 블럭 수
          + 블럭 : 데이터베이스에 데이터가 저장되는 최소 단위

      + 컬럼
        + 컬럼의 종류
        + not null의 분포도

      + 인덱스
        + Leaf Page의 개수
        + Level 정보

      + 시스템
        + I/O 성능 및 사용량
        + CPU 성능 및 사용량

  + 옵티마이저의 한계
    + 옵티마이징 팩터
      + 옵티마이저는 주어진 환경에서 최적의 처리 경로를 생성한다. 그렇기 때문에 사용자가 인덱스, 파티셔닝과 같은 옵티마이징 팩터를 제공해주지 않는다면 더 좋은 최적화를 생성할 수 없다.

    + 통계정보의 부정확성
      + 최적화에 필요한 모든 정보를 수집하고 저장하면 좋지만, 100% 완벽한 통계정보를 수집 및 저장하는 것은 어렵고 비용이 많이 들게 된다.

    + 하드웨어 성능




</details>

-----------------------

<br>



<br>

-----------------------

### 관계형 DB, No SQL

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- RDB (Relation Data Base)
  - 정해진 스키마에 따라 데이터를 테이블에 저장하는 데이터베이스
  - 데이터 구조를 보장하고 중복을 방지한다.
  - 테이블간의 연관관계를 가진다.
  - 수직적 확장이 가능하다 (성능 향상)
  - 사용
    - 관계를 맺고 있는 데이터의 수정이 빈번한 경우
    - 명확한 스키마가 데이터와 사용자에게 중요한 경우
- No SQL
  - 유연한 스키마로 데이터간의 관계없이 자유로운 형태로 데이터를 저장하는 데이터베이스
  - 수평적 확장으로 트랜픽 분산 및 대용량 처리가 가능하다.
  - 사용
    - 읽기를 많이하고 수정, 삭제가 많이 없는 경우
    - 데이터베이스를 수평적으로 확장해야 하는 경우 (막대한 양의 데이터를 다룸)


</details>

-----------------------

<br>



<br>

-----------------------

### Redis, Memcached, MongoDB

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ Redis
  + In Memory 데이터베이스로  key,value 형태로 데이터를 저장하는 NoSQL이다.
    + 데이터를 메모리에 저장하여 빠르게 접근 할 수 있다.
  + 여러가지 자료구조(String, LinkedList, Set, Sorted Set..), 싱글스레드를 제공하여 일관성 문제가 발생하지 않고 각 자료구조는 atomic critical section(critical section에 동기화)을 제공한다.
  + 스냅샷을 통해 디스크에 저장이 가능하다.
+ Memcached
  + In Memory 데이터베이스로 key,value 형태로 데이터를 저장하는 NoSQL이다.
  + 멀티 스레드를 제공하는 고성능 분산 메모리 캐싱 시스템
  + 복제 기능을 지원해주지 않는다.
  + 시스템에서 사용되지 않는 일부 메모리를 활용할 수 있어서 성능 향상 가능
+ In Memory 데이터베이스란
  + 메인 메모리에 데이터를 저장하여 디바이스 데이터베이스보다 더 빠르게 데이터를 가져오는 데이터베이스
  + 데이터 베이스의 부하를 줄여 애플리케이션의 속도 개선을  위해 사용된다.
+ MongoDB
  + JSON과 유사한 도큐먼트를 사용하여 스키마없이 데이터를 저장한다.
  + 물리 디스크 사용





</details>

-----------------------

<br>



<br>

-----------------------

### Elastic Search

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 자바 기반의 오픈 소스 검색 엔진으로 역색인을 통해 방대한 양의 데이터를 빠르게 검색, 저장할 수 있다.
+ <img width="446" alt="image" src="https://user-images.githubusercontent.com/57162257/185732856-30c0b5c3-d2e3-4ce1-80f5-225017db987b.png">
+ 역색인
  + 텍스트를 파싱해서 단어를 분리하여 검색어 사전에 저장한다.
  + 검색어 사전에는 단어별로 Document를 가리키고 있다.
  + <img width="442" alt="image" src="https://user-images.githubusercontent.com/57162257/191022507-4fdc60bf-c064-4c49-b959-1924d587231d.png">
  
+ 구조
  + Cluster
    + Elastic Search에서 가장 큰 시스템 단위
    + 하나 이상의 Node를 가지고 있으며, Cluster끼리는 통신이 불가능하다.

  + Node
    + 하나의 단위 프로세스로써 Index 생성, 데이터 CRUD 등의 역할에 따라 노드를 나눈다.

  + Index
    + 데이터베이스와 대응하는 개념
    + Index = DataBase, Type = Table, Field = Colume, Document = Row

  + Shard
    + 샤딩을 통해 Index를 분리하여 저장한 형태
    + 스케일 아웃을 위해 index를 여러 shard로 나눈다.

  + Replica
    - Node의 손실을 대비하기 위해 shard를 여러 Node에 저장한 것.

+ 특징
  + Scale Out
    + 샤드를 통해 수평적 확장

  + 고가용성
    + 레플리카를 통해 안정성 보장

  + Schema Free
    + Json문서로 검색하기 때문에 스키마가 없다.

  + Rest Ful
    + 데이터 crud 작업은 http restful api를 사용한다.
    + SELECT = Get, Create = Put, UPDATE = Post, DELETE = Delete
      + Put으로 저장할때는 index/type/id 로 id를 제어할 수 있다.
      + Post로 저장할때는 index/type로 id 생성 제어를 넘긴다.
    + 저장 : index / type / id
    + 조건 조회 : index / _search ? age=80 등의 url search나 json파일에 쿼리를 작성해서 POST로 검색하는 방법이 있다.



</details>

-----------------------

<br>



<br>

-----------------------

### Elastic Search & RDBMS의 Like

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ RDBMS의 Like는 전체검색으로 단순 텍스트 매칭에 대한 결과를 반환
+ Elastic Search는 전체검색이 아닌 역색인 기반으로 검색하기 때문에 빠르다.


</details>

-----------------------

<br>



<br>

-----------------------

### 샤딩

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 큰 테이블을 수평으로 쪼개어 다른 데이터베이스에 저장하는 방법
+ 장점
  + 데이터와 Index의 개수가 줄어들어 성능이 향상된다.

+ 단점
  + 데이터베이스 간의 통신이 많아져 비용 증가
  + 하나의 서버가 고장나면 무결성이 깨질 수 있다.



</details>

-----------------------

<br>



<br>

-----------------------

### 수평 파티셔닝

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 테이블을 수평으로 나누어 스키마가 동일한 여러 테이블을 만드는것.
+ 장점
  + 데이터와 Index의 개수가 줄어들어 성능이 향상된다.

+ 단점
  + 데이터를 찾는 과정이 기존보다 복잡해 처리 시간이 증가한다.



</details>

-----------------------

<br>



<br>

-----------------------

### 수직 파티셔닝

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ 테이블을 수직으로 나누어 여러 테이블로 분리하는 방식
+ 장점
  + 자주 사용하는 컬럼을 분리시켜 조회시 필요없는 데이터가 올라오는 것을 줄여 성능을 높여준다.

+ 단점
  + 테이블간 조인 비용 발생



</details>

-----------------------

<br>



<br>

-----------------------

### 클러스터링

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ <img width="400" alt="image" src="https://user-images.githubusercontent.com/57162257/193442820-ee614ba1-3bf5-40e3-9ff5-d547174b343e.png">
+ 동일한 DB 스토리지를 이용하고 다수의 DB 서버를 사용하는 방식
+ Sync방식으로 동기화한다.
+ Active-Active 방식
  + 여러대의 DB 서버가 트래픽을 분산해서 받는다.
  + 하나의 DB 스토리지를 사용하기 때문에 병목현상이 발생할 수 있다.

+ Active-Standby방식
  + 한쪽은 Standby상태로 두어 Active상태의 서버가 죽으면 FailOver되어 전환되는 방식
  + FailOver가 이루어지는 동안 손실이 존재한다.




</details>

-----------------------

<br>



<br>

-----------------------

### 래플리케이션

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />




-----------------------

+ <img width="400" alt="image" src="https://user-images.githubusercontent.com/57162257/193442910-09cd777b-5235-458e-84d5-bba0b2403e2b.png">
+ DB서버와 DB스토리지를 다중화하는 방법.
+ SELECT는 SLAVE에서 INSERT,UPDATE,DELETE 작업은 MASTER에서 수행하면서 트래픽 분산
+ SLAVE로 데이터를 동기화할때 비동기화 작업으로 수행하기 때문에 일관성 있는 데이터를 얻지 못할 수도 있다.
+ Master 노드가 다운되면 복구 및 대처가 까다롭다.



</details>

-----------------------

<br>



<br>

-----------------------

### RabbitMQ & Kafka

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

+ Message Queue 기반의 메시지 시스템
+ Message Queue
  + 프로세스간 데이터를 교환할 때 사용하는 통신 방법
  + 장점
    + 비동기 : 메시지를 queue에 저장
    + 낮은 결합도 : 애플리케이션과 분리
    + 탄력성 : consumer가 고장나도 메시지는 queue에 저장되어있음
    + 보장성 : MQ에 저장되면 모든 메시지는 consumer에게 전달 보장

+ Kafka
  + <img width="600" alt="image" src="https://user-images.githubusercontent.com/57162257/187015445-92ffd37c-dee0-40d1-ae7a-acef0cf0ab8f.png">
  + 메시지 큐 기반의 분산 메시징 시스템
  +  Publisher와 Subscriber를 중심으로 생성자가 원하는 메시지를 배포 패턴으로 진행
  + 메시지를 Subscriber가 가져가도 broker에서는 메시지를 저장하고 있어 다시 사용가능
  + 메시지를 병렬 처리하기 때문에 대용량 데이터 처리 가능
  
+ RabbitMQ
  + <img width="500" alt="image" src="https://user-images.githubusercontent.com/57162257/187015453-9dfe5634-e563-4906-93fa-3e868acb2e36.png">
  + AMQP 프로토콜을 구현한 메시지 브로커
    + AMQP : client와 broker간 메시지를 주고받기 위한 프로토콜
  + 브로커 중심적 형태로 producer와 consumer간 보장된 메시지 전달에 초점
  + 메시지를 consumer에게 전달하면 삭제
  + 데이터 처리보다 Manage UI를 제공해 관리나 다양한 기능 제공을 위한 서비스 구축에 사용



</details>

-----------------------

<br>





