# 운영체제(OS)



<br>

-----------------------

### 운영체제란

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 컴퓨터의 하드웨어와 소프트웨어가 통신하고 작동할수 있도록하는 소프트웨어 환경
- 목적
  - 컴퓨터의 계산 활동을 관리하여 컴퓨터 시스템이 제대로 작동하도록 한다.
  - 프로그램의 개발 및 실행을 위한 환경 제공.

</details>

-----------------------

<br>



<br>

-----------------------

### 프로세스와 스레드

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 프로세스 : 메모리에 올라와서 실행되는 프로그램의 실행 단위
- 스레드 : 프로세스 안에서 역할을 수행하는 흐름 단위, 다른 스레드와 자원 공유 가능
- 스레드는 메모리에서 stack만 할당 받으며, 프로세스의 code, data, heap영역의 메모리를 공유한다.

</details>

-----------------------

<br>



<br>

-----------------------

### 멀티프로세스와 멀티스레드

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 멀티 프로세스
  - 하나의 프로그램이 여러개의 프로세스로 구성되어 프로그램을 병렬적으로 작업 수행
  - 멀티 프로세스는 하나의 프로세스에 문제가 발생하면 다른 프로세스에 영향을 미치지 않지만 멀티 스레드보다 많은 메모리를 필요로 한다.
- 멀티 스레드
  - 하나의 프로세스에서 여러개의 스레드로 구성되어 자원을 공유하며 작업을 수행
  - 멀티 프로세스보다 적은 메모리를 필요로 하지만 하나의 스레드에 문제가 발생하면 다른 스레드에 영향을 미쳐 프로그램이 종료될수 있다.

</details>

-----------------------

<br>



<br>

-----------------------

### 멀티 프로세스보다 멀티 스레드를 사용하는 이유

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 멀티 스레드 사용시, 프로세스를 생성시 자원을 요청하는 system call이 줄어들어 자원을 효율적으로 관리할 수 있다. 
- 멀티 스레드는 공유 자원을 사용하기 때문에 통신 비용이 적게 든다.
- 컨텍스트 스위칭시 stack영역만 초기화 하면 된다.

</details>

-----------------------

<br>



<br>

-----------------------

### 스레드마다 stack을 독립적으로 할당하는 이유

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- stack을 독립적으로 할당한다는 것은 함수를 독립적으로 실행하는 것이 가능해진다. 이는 독립적인 실행 흐름을 추가하는것이다.
- 즉, 독립적인 실행 흐름을 추가하기 위해 스레드마다 stack을 할당해준다.

</details>

-----------------------

<br>



<br>

-----------------------

### 스레드마다 PC Register를 독립적으로 할당하는 이유

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 스레드의 pc에는 명령을 어디까지 수행했는지 저장하는 부분이다.
- 프로세스는 cpu에 할당되었다가 스케줄러에 의해서 선점된다. 그래서 스레드는 명령을 한번에 처리를 하지 못하는 경우가 있는데, 명령 수행 위치를 저장해놔야 다음 cpu에 할당되었을때 명령을 이어서 수행할 수 있다.

</details>

-----------------------

<br>



<br>

-----------------------

### 자바 스레드

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 일반 스레드와 동일하게 프로그램의 흐름 단위.
- JVM에 의해 관리되며 JVM은 프로세스가 없고 스레드만 존재한다.
- 스레드가 생성되면 스레드 정보를 Thread Control Block에 저장하고 JVM에 의해 관리된다.

</details>

-----------------------

<br>



<br>

-----------------------

### 메모리(RAM)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

<img width="30%" alt="image" src="https://user-images.githubusercontent.com/57162257/182611233-ad4eacd7-2f5b-4957-8146-8e481339fc67.png">

- 코드 영역 : 실행한 프로그램의 코드 저장 영역
- 데이터 영역 : 전역 변수, 정적 변수 저장 영역
- 힙 영역  : 개발자의 동적으로 할당되는 데이터 저장 영역, 런타임시 크기가 결정된다.
  - 장점: 필요한 데이터의 크기를 알 수 없을 때 사용가능
  - 단점: 힙 경합시 속도 저하 (여러 스레드가 힙 영역의 데이터를 동시에 접근하는 문제)
- 스택 영역 : 지역변수, 매개변수 저장 영역, 컴파일시 크기가 결정된다.
  - 장점: 낭비되는 공간이 없다
  - 단점: 공간을 유연하게 사용할 수 없다.



</details>

-----------------------

<br>



<br>

-----------------------

### 기억장치

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 데이터, 프로그램, 연산 중간 결과등을 일시적 또는 영구적으로 저장하는 장치
- 레지스터 : CPU에 있는 작지만 빠른 기억장치
- 캐시 : CPU 주기억장치의 접근속도 차이를 해결하기 위한 저장소
- 주 기억장치 : CPU가 직접 읽고 쓸수 있는 장치 (RAM, ROM), 레지스터에 비해 속도가 느리다.
- 보조 기억장치 : CPU가 직접 일고 쓸수 없지만 대용량인 저장소

</details>

-----------------------

<br>



<br>

-----------------------

### 가상 메모리

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 프로세스 전체가 메모리에 올라오지 않고 실행에 필요한 부분만 메모리에 올려서 프로그램을 실행 시킬수 있는 기법
- 가상 메모리가 없다면 프로세스 전체를 메모리에 올려서 사용해야하기 때문에 메모리의 크기에 제약이 많이 따른다.
- 가상 메모리를 사용하게 되면 프로세스에서 필요한 부분만 메모리에 올려서 프로그램을 실행할 수 있기 때문에 메모리의 크기에 제약을 받지 않는다.
- CPU이용률과 처리량이 높아졌다.
- 페이징을 통해 필요한 프로세스를 메모리에 올린다.
- 하지만 물리 메모리로 프로세스를 구동시키는 것보다 느리다.

</details>

-----------------------

<br>



<br>

-----------------------

### 요구 페이징

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- CPU가 프로세스를 실행시킬때 필요한 데이터(페이지)를 메모리에 적재하는 전략
- 가상 메모리는 페이징으로 관리된다.
- 페이지 부재(page fault) 발생시 mmu(memory management unit)에 의해서 인터럽트를 발생시켜 프로세스를 wait상태로 변경 한 후, 요구하는 페이지를 메모리에 올리고 다시 실행한다.

</details>

-----------------------

<br>



<br>

-----------------------

### 메모리 관리 전략

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 제한된 메모리를 효율적으로 사용하고 관리하기 위한 전략
- 문제
  - 내부 단편화 : 메모리에 남은 공간이 너무 작아 다른 프로세스가 할당될수 없는 것
  - 외부 단편화 : 프로세스의 크기보다 크게 메모리 공간이 남아있어도 실질적으로 메모리에 프로세스를 할당할 수 없는 것

- 연속 메모리 할당 : 프로세스를 메모리에 연속적으로 할당하는 방법 (외부 단편화 발생)
  - First Fit : 가장 먼저 만나는 빈 메모리 공간에 할당
  - Best Fit : 프로세스 크기와 빈 메모리 공간의 차이가 가장 적은 곳에 할당
  - Worst Fit : 프로세스 크기와 빈 메모리 공간의 차이가 가장 많은 곳에 할당
- 페이징
  - <img width="50%" alt="image" src="https://user-images.githubusercontent.com/57162257/182620581-854c2f6b-5d2f-4096-86c8-6ed4e10c8830.png">
  - 프로세스를 일정 크기인 페이지로 나누고 물리 메모리도 동일한 크기인 프레임으로 나눈다.
  - CPU는 연속적인 논리 메모리로 메모리에 접근하지만 MMU의 페이지 테이블을 사용해서 논리메모리를 물리메모리로 변경하여 나뉘어져있는 프로세스 정보에 접근할 수 있다.
- 세그먼트
  - <img width="60%" alt="image" src="https://user-images.githubusercontent.com/57162257/182623165-5c221ef4-bed9-4079-b7bb-3b65a1282c67.png">
  - 페이징과 반대로 프로세스를 고정되지 않는 크기의 세그먼트 단위로 나누어 메모리에 불연속적으로 저장하는 방식.
  - CPU는 논리주소로 메모리에 접근하고 MMU의 세그먼트 테이블을 통해 논리주소를 물리주소로 변경하여 물리 메모리에 저장되어있는 프로세스 정보에 접근할 수 있다.
  - 세그먼트 테이블의 limit를 초과하게 되면 인터럽트에 의해 프로세스가 강제 종료된다.

</details>

-----------------------

<br>



<br>

-----------------------

### 페이지 교체 알고리즘

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 가상 메모리를 관리하는 페이징 기법에서 페이지를 교체할때 사용하는 알고리즘
- 종류
  - FIFO (First In First Out) : 가장 먼저 들어온 페이지가 가장 먼저 교체된다.
  - LRU (Least Recently Use) : 최근에 가장 오랫동안 사용하지 않은 페이지가 교체된다. (가장 많이 사용)
  - LFU (Least Frequently Use) : 최근에 사용빈도가 가장 적은 페이지가 교체된다.
  - OPT (Optimal) : 앞으로 가장 오랫동안 사용하지 않을 페이지를 예상해서 교체된다. (연구목적)
  - NRU (Not Recently Use) : LRU와 동일하게 최근에 사용한지 오래된 페이지를 교체하는데, 참조비트와 변형 비트를 사용해서 LRU의 오버헤드를 줄인 알고리즘
    - 참조 비트 : 페이지에 참조했다면 1, 참조하지 않았다면 0
    - 변형 비트 : 페이지 내부 내용이 변경되었다면 1, 변경되지 않았다면 0
    - 참조 비트의 0이 변형비트의 0보다 교체 우선순위가 높다.

</details>

-----------------------

<br>



<br>

-----------------------

### Trashing

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 페이지 부재가 빈번하게 발생하면, 프로세스 실행 시간보다 페이지 교체 시간이 더 많은 상태
- 해결방법
  - 다중 프로그래밍 빈도를 줄인다.
  - Working Set 알고리즘
    - 특정 기간동안 사용되는 페이지 개수를 파악해서 해당 페이지 개수만큼의 프레임이 확보된다면 페이지를 메모리에 올리는 알고리즘
  - Page Fault Frequency 알고리즘
    - page fault 퍼센트의 상한과 하한을 지정한 후, 상한을 넘게된다면 주어지는 프레임의 개수를 늘려주고 하한을 넘게된다면 주어지는 프레임의 개수를 줄이는 알고리즘

</details>

-----------------------

<br>



<br>

-----------------------

### 프로세스 상태

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 생성 : 프로세스가 생성되는 상태
- 준비 : 프로세스가 CPU에 실행되고 있는 상태는 아니지만 언제든지 CPU에 할당될수 있는 상태
- 실행 : CPU에 할당되어 작업을 수행하는 상태
- 대기 : 입출력과 같은 인터럽트에 의해서 프로세스가 대기중인 상태
- 종료 : 프로세스의 작업이 끝나 종료된 상태

</details>

-----------------------

<br>



<br>

-----------------------

### 스케줄러

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 프로세스를 스케줄링 하기 위해 3개의 큐가 존재한다
  - Job Queue : 존재하는 모든 프로세스를 담은 큐
  - Ready Queue : CPU할당을 대기하는 프로세스를 담은 큐
  - Device Queue : Device IO 출력을 위해 대기하고 있는 프로세스를 담은 큐

- 이 큐를 관리해주기 위해 3개의 스케줄러가 존재한다.
- 장기 스케줄러 : 디스크 내의 프로세스를 메모리에 가져올지 결정하여 프로세스를 준비 상태로 보내는 스케줄러
- 단기 스케줄러 : Ready Queue에 존재하는 프로세스 중 CPU에 할당될 프로세스를 정하는 스케줄러
- 중기 스케줄러 : CPU에 할당되기 위해 너무 많은 프로세스가 몰리게 되면 메모리를 관리하기 위해 프로세스를 디바이스 영역으로 보내는 스케줄러
  - Swap out : 디바이스 영역으로 보냄
  - swap in : 메모리로 다시 들임

</details>

-----------------------

<br>



<br>

-----------------------

### 인터럽트

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- CPU가 프로세스를 처리하고 있을 때, 입출력이나 예외가 발생하면 해당 이슈를 처리하기 위해 CPU에게 알려주는 것
- 종류
  - 외부 인터럽트 : 입출력, 하드웨어 문제 발생시
  - 내부 인터럽트 : 잘못된 명령이나 데이터를 사용할때 발생
  - 시스템 인터럽트 : system call 발생시
- 인터럽트 수행 과정
  1. CPU 실행 중 인터럽트 발생
  2. 수행중인 프로세스를 멈추고 상태 레지스터와 pc 등을 저장한 후, 인터럽트 서비스 루틴으로 이동
  3. 인터럽트로 요청된 작업 수행
  4. 완료 후, 저장된 프로세스 정보를 가져와 다시 수행.

</details>

-----------------------

<br>



<br>

-----------------------

### CPU 스케줄링

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 대기하고 있는 프로세스를 CPU에 할당시키는 스케줄링으로써, 단기 스케줄러에 의해 수행되며 CPU의 선점 여부에 따라서 선점 스케줄링과 비선점 스케줄링으로 나뉜다.
- 종류
  - 선점 스케줄링 : CPU의 제어권을 뺏음
  - 비선점 스케줄링 : CPU의 제어권을 뺏지 않음
- 비선점 스케줄링
  - FCFS (First Come First Service) : CPU를 요청한 순서대로 CPU에 할당
  - SJF (Short Job First) : CPU 요구량이 가장 적은 프로세스부터 할당
  - HRN (Highest Response-Ratio Next) : 우선순위를 계산하여 점유 불평등을 보완하는 방법
    - 우선순위 = (대기시간 + 실행시간)/실행시간
- 선점 스케줄링
  - 라운드 로빈 (Round Robine) : FCFS처럼 CPU를 요청한 순서대로 할당하지만, 각 프로세스마다 할당가능한 시간을 주고 선점하는것.
  - SRT (Shortest Remaning Time) : SJF처럼 CPU요구량이 적은 프로세스부터 할당하지만, 중간에 더 적은 프로세스가 있다면 선점하는것.
  - 다단계 큐 (Multi-level Queue) 
    - 각 큐마다 절대적인 우선순위와 스케줄링을 적용하며 프로세스는 종류와 우선순위에 따라 큐에 배치된다.
    - 각 큐마다 프로세스는 이동할 수 없기 때문에 스케줄링 부담은 적지만 유연함이 부족하다.
  - 다단계 피드백 큐 (Multi-level Feedback Queue)
    - 각 큐마다 절대적인 우선순위와 스케줄링을 적용한다.
    - 하지만 각 큐마다 프로세스가 이동할 수 있기 때문에 기아현상을 방지하고 유연하게 CPU에 할당할수 있다.

</details>

-----------------------

<br>



<br>

-----------------------

### 커널

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 기본적으로 소프트웨어는 메모리에 올라가있어야지 컴퓨터 시스템상에서 작동할 수 있다.
- 운영체제도 소프트웨어이기 때문에 메모리에 올라가있어야 실행되는데, 모든 운영체제를 메모리에 올리게 되면 메모리 낭비가 심하기 때문에 운영체제 중 항상 필요한 부분만 메모리에 올라가 있는데 이를 커널이라고 한다.
- 즉, 메모리에 상주하고 있는 운영체제의 핵심 부분

</details>

-----------------------

<br>



<br>

-----------------------

### System Call

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 운영체제는 기능을 제한하여 보안을 하기 위해 커널 모드와 사용자 모드로 나누어 구동한다.
- 시스템 콜은 커널 모드의 기능을 사용자 모드에서 사용하기 위해 프로세스가 운영체제에게 요청하는 인터페이스.
- 분류
  - 프로세스 제어
    - fork
      - 프로세스의 생성과 제어를 위한 시스템 콜
      - 새로운 프로세스를 만드는 것
      - PCB/프로세스 메모리 구조가 복사된다.
    - exec
      - 프로세스의 생성과 제어를 위한 시스템 콜
      - 프로세스를 새로운것으로 덮어씌워 실행시키는 것
      - 새로운 메모리를 할당하지 않고 현재 프로세스를 덮어 씌워 실행
  - 파일 조작
  - 장치 관리
  - 정보 유지
  - 통신

</details>

-----------------------

<br>



<br>

-----------------------

### PCB (Process Control Block)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- PCB는 프로세스의 정보인 Process Metadata를 저장하는 곳
- 커널내에 존재하는 하나의 자료구조
- LinkedList로 관리되어 삽입과 삭제에 효율적이다.
- Process Meta Data
  - Process ID
  - Process State
  - Process Priority
  - Program Count : 다음에 실행할 명령어 주소

</details>

-----------------------

<br>



### PCB 필요한 이유

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- context switching시 실행중인 프로세스의 정보를 저장하고 다음 프로세스를 실행시킬 때 PCB를 이용해 프로세스의 정보를 저장하고 불러온다.

</details>

-----------------------

<br>



### PCB 저장과정

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

1. 프로그램 실행
2. 프로세스 생성
3. 프로세스 메모리 (code, data, stack) 공간 할당
4. 프로세스의 메타데이터가 커널의 PCB에 저장

</details>

-----------------------

<br>



<br>

-----------------------

### Context Switching

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 스케줄링에 따라 실행중인 프로세스의 정보를 저장하고 새로운 프로세스의 정보를 CPU에 넘겨주는 작업 과정
- CPU가 교체되는 프로세스의 정보를 PCB에 저장하고, 새로운 프로세의 정보를 PCB에서 불러와 CPU의 레지스터에 적재
- 인터럽트가 발생하면 인터럽트 처리를 수행하기 전에 발생

</details>

-----------------------

<br>



<br>

-----------------------

### Context Switching 발생 과 비 발생

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 발생
  - Dispacher에 의해서 Ready Queue의 프로세스가 CPU에 할당될 때
  - Time 인터럽트 발생 시
  - 입출력 요청 system call 발생 시
- 비발생
  - Time 인터럽트를 제외한 인터럽트
  - 입출력 요청 system call을 제외한 system call
  - 두 경우시 모두 운영체제가 커널모드로 변경되어 실행될 뿐 실행중인 프로세스를 중단했다가 요청을 처리한 후 다시 실행한다.

</details>

-----------------------

<br>



<br>

-----------------------

### Context Switching 오버헤드

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- context swtiching시 새로운 프로세스 정보를 CPU의 레지스터에 적재할 때 CPU는 아무런 작업을 할 수 없다.
- 이 때를 context switching의 오버헤드라고 한다.
- 해결 방안
  - 다중 프로그래밍 수준을 낮추어 context switching 발생 빈도를 줄인다.
  - 스레드를 이용해서 context switching 부하를 최소화한다.
    - 스레드는 프로세스와 다르게 공유 메모리 공간이 있기 때문에 context switching이 발생해도 캐시 데이터를 공유 자원에 저장하고 있기 때문에 비용적으로나 시간적으로나 효율적이게됩니다.

</details>

-----------------------

<br>



<br>

-----------------------

### Dispatcher

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 스케줄러가 Ready 상태의 프로세스 중 하나를 CPU에 할당시켜 Run 상태로 변경하는 요소를 Dispatcher라고 한다.
- dispatcher가 Ready 상태의 프로세를 CPU에 할당하는데 까지 걸리는 시간을 Dispatcher Latency라고 한다.
- Ready상태의 프로세를 Run상태로 변경하는 것을 Dispatcher가 수행하고 실행중인 프로세스의 정보를 PCB에 저장하고 새로운 프로세스의 정보를 PCB에서 가져와 실행시키는 모든과정을 Context Swtiching이라고 한다.
- 즉, Context Switching과정에 Dispatch 과정이 포함된 구조이다.

</details>

-----------------------

<br>



<br>

-----------------------

### Synchronization (동기화)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 프로세스 동기화 : 하나의 자원을 동시에 여러 프로세스가 동시에 접근하는것을 제어
- 스레드 동기화 : 하나의 코드블럭 또는 메소드를 여러 스레드가 동시에 접근하는 것을 제어
- 동기화 방법 : 뮤텍스, 세마포어

</details>

-----------------------

<br>



<br>

-----------------------

### 뮤텍스 & 세마포어

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 뮤텍스와 세마포어는 여러개의 프로세스나 스레드가 공유자원에 동시에 접근하는 것을 막기위한 방법
- 뮤텍스 (Mutex) : 오직 한개의 프로세스나 스레드 만이 공유자원에 접근하도록 제어하는 것. 동기화 대상이 하나이다.
- 세마포어 (Semaphore) : 세마포어 변수만큼의 스레드나 프로세스가 접근할수 있도록 제어하는 것. 동기화 대상이 여럿일 수 있다.

</details>

-----------------------

<br>



<br>

-----------------------

### 교착상태(Dead Lock)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 두개 이상의 프로세스나 스레드가 자원을 점유한 상태에서 서로의 자원을 점유하기 위해 기다려서 무한한 대기가 발생하는 것.
- 발생 조건
  - 상호 배제 (Mutual Exclusion) : 하나의 자원에 여러 프로세스의 동시접근을 막는것.
  - 점유와 대기 (Hold and Wait) : 하나의 자원을 점유하고 다른 프로세스의 자원을 요청하는 것.
  - 비선점 (Non Primitive) : 점유하고 있는 자원의 제어권을 뺏을수 없는 것
  - 환영 대기 (Circle Wait) : 각 프로세스가 다음 프로세스가 요청하고 있는 자원을 점유하는 것
- 해결방법
  - 예방 (Prevention) : 4가지의 발생 조건 중 하나를 해결하여 예방하는 것.
  - 회피 (Avoidance) : 발생하지 않도록 알고리즘을 설계하여 교착상태를 피하는 것.
    - 은행원 알고리즘 : 자원을 할당한 후에도 안정 상태로 유지되는지 사전에 검사하여 교착상태를 회피하는 것.
  - 탐색 (Detection) : 자원할당 그래프를 모니터링 해서 교착상태를 탐지하는 것
  - 회복 (Recovery) : 교착 상태가 탐지되면 복구를 실행.

</details>

-----------------------

<br>



<br>

-----------------------

### IPC (Inter Process Communication)

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 독립적인 프로세스간 통신하기 위한 설비
- 프로세스는 커널에서 제공해주는 IPC 설비를 통해 프로세스간 통신이 가능하다.
- IPC에서는 프로세스간 데이터를 동기화하고 보호하기 위해서 뮤텍스와 세마포어를 사용한다.
- 종류
  - 익명 Pipe
    - 두개의 프로세스를 연결하여 한쪽에서는 쓰기만, 다른 한쪽에서는 읽기만 가능한 반이중 통신.
    - 전이중 통신을 위해서는 2개의 파이프가 필요하다.
    - 통신할 프로세스간의 관계가 명확한 상태에서만 사용할 수 있다. (부모-자식 프로세스 관계)
  - Named Pipe
    - 익명 Pipe와 마찬가지로 반이중 통신.
    - 전이중 통신을 위해서는 2개의 파이프가 필요하다.
    - 두 프로세스간 관계가 명확하지 않아도 통신이 가능하다.
  - Message Queue
    - Pipe는 데이터의 흐름이고 Message Queue는 메모리 공간을 가진다.
    - 메세지에 데이터를 담은 후 번호를 남기고 전역으로 관리되는 하나의 큐를 통해 여러 프로세스가 동시에 데이터를 주고 받을수 있다.
  - Shared Memory
    - Pipe와 Message Queue는 통신을 위한 설비라면, Shared Memory는 데이터 자체를 공유하기 위한 설비이다.
    - 프로세스간 메모리 영역을 공유해서 같이 사용할 수 있도록 허용한다.
    - 중계자 없이 데이터를 공유하기 때문에 IPC 중 가장 빠르다.
  - Socket
    - 네트워크 소켓 통신을 통해 데이터 공유
    - 원격에서 프로세스간 데이터를 공유할때 사용한다.

</details>

-----------------------

<br>



<br>

-----------------------

### Race Condition & Critical Section

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- Race Condition
  - 공유되는 자원에 대해 여러개의 프로세스가 동시에 접근했을 때 반환되는 결과를 보장할 수 없는 상태
  - Race Condition을 잘 해결하기 위해서는 공유되는 영역인 임계영역 (Critical Section)의 문제를 잘 해결해야 한다.
- Critical Section (임계 영역)
  - 여러 프로세스에게 공유되는 영역
- 임계 영역을 해결하기 위한 조건
  - 상호 배제 (Mutal Exclusion) : 하나의 프로세스가 임계영역에 있다면 다른 프로세스의 접근을 막는것.
  - 진행 (Progress) : 임계영역에 들어갈 프로세스가 여러개 일때 어떤 것이 들어가야하는 지 결정해야 한다.
  - 한정 대기 (Bounded Waiting) : 임계영역에 들어갔다온 프로세스는 다음 접근에 제한을 받음.

</details>

-----------------------

<br>



<br>

-----------------------

### CPU 성능 척도

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- CPU Utilization (이용률) : CPU가 쉬지않고 일한 시간
- Thorughput (처리량) : 단위 시간 처리량
- Turnaround Time (소요시간) : 프로세스의 CPU사용시간 + 대기 시간
- Waiting Time (대기시간) : 프로세스가 Ready Queue에서 대기한 총 시간
- Response Time (응답시간) : 프로세스가 최초 Ready Queue에 들어가서 CPU에 할당되기까지 걸린 시간

</details>

-----------------------

<br>



<br>

-----------------------

### 캐시

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- CPU가 주기억장치에 접근하는 횟수를 줄여주기 위해 주기억장치의 특정 정보를 저장하는 저장소로 캐시 지역성을 통해 주기억장치의 특정 정보를 캐시에 저장한다.

</details>

-----------------------

<br>



<br>

-----------------------

### 캐시 지역성

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 캐시는 사용 예상되는 데이터를 저장하여 CPU의 처리속도를 빠르게 도와준다.
- CPU가 캐시를 참조했을때 쓸모있는 정보에 따라 처리속도가 달라진다.
- 적중률(Hit rate)를 극대화시키기 위해 데이터의 지역성을 사용한다.
- 지역성
  - 시간 지역성 : 최근에 참조된 데이터는 곧 다시 참조되는 특징
  - 공간 지역성 : 참조된 데이터의 인근 데이터가 참조되는 특징
- 지역성을 이용해 데이터를 캐시에 담고있다면 적중률을 높일수 있다.

</details>

-----------------------

<br>



<br>

-----------------------

### 기아현상 & 에이징 기법

<details>
   <summary> 예비 답안 보기 (👈 Click)</summary>
<br />



-----------------------

- 기아현상 : 프로세스의 할당 우선순위가 낮아 지속적으로 CPU의 할당을 받지 못하는 문제
- 에이징 기법 : 기아현상을 해결하기 위한 방법으로 프로세스의 할당 우선순위를 대기시간에 비례하여 점진적으로 높여주어 CPU에 할당될수 있도록 하는 방법

</details>

-----------------------

<br>